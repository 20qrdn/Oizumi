{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c0da6c",
   "metadata": {},
   "source": [
    "# 五章　誤差逆伝播法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fd2898",
   "metadata": {},
   "source": [
    "四章で実装した勾配降下法を用いたニューラルネットワークの学習は、**数値微分**を利用したことで計算に多くの時間がかかりました。そこで今回は**誤差逆伝播法**を用いて高速かつ効率的に勾配を求めてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff343aa1",
   "metadata": {},
   "source": [
    "## 計算グラフ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a479f0",
   "metadata": {},
   "source": [
    "![計算グラフ](https://cdn-ak.f.st-hatena.com/images/fotolife/l/losiz17/20180312/20180312192958.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a8d9d1",
   "metadata": {},
   "source": [
    "**計算グラフ**とは、計算の過程を上記の図のように表したものです。演算の内容が書かれている円を**ノード**、ノード間を結ぶ直線を**エッジ**と呼びます。基本的に左から右へ計算は進められ、そのことを**順伝播**といいます。一方でその逆は**逆伝播**といいます。これが今章で大事になってきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eca4ca",
   "metadata": {},
   "source": [
    "逆伝播は上の図で書かれた右から左のエッジです。一つ一つのエッジは微分の式($ \\frac{\\partial y}{\\partial x} $)で表され、逆伝播はこの微分の式をかけることで行われます。この性質を**連鎖律の原理**と呼び、**合成関数**の考え方が使われています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458907ba",
   "metadata": {},
   "source": [
    "## 逆伝播"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2221f",
   "metadata": {},
   "source": [
    "ここから先は様々な演算の逆伝播を見ていきます。最初は四則演算からです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790aec64",
   "metadata": {},
   "source": [
    "加算ノードの逆伝播は非常にシンプルです。例として、上記にもある$ t=x+y $の数式を偏微分してみると、"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931548fe",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\frac{\\partial t}{\\partial x}=1 \\\\\n",
    "    \\frac{\\partial t}{\\partial y}=1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cdf337",
   "metadata": {},
   "source": [
    "となります。これは加算の逆伝播は値がそのまま伝わることが分かります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d56e0eb",
   "metadata": {},
   "source": [
    "続いて乗算ノードの逆伝播です。ここでは$ z=xy $という式を例にとって考えてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179cc0df",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\frac{\\partial z}{\\partial x}=y \\\\\n",
    "    \\frac{\\partial z}{\\partial y}=x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828e0fb",
   "metadata": {},
   "source": [
    "この式からは、乗算ノードの逆伝播が順伝播の時の入力信号を逆に掛けて伝わることになると分かります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa2c22",
   "metadata": {},
   "source": [
    "一度これまで習った計算グラフの考え方を具体例を使って表してみます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097678be",
   "metadata": {},
   "source": [
    "![計算グラフ 具体例](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/470838/a5e0cc17-3e26-3e22-140c-627cb7a149ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7084418",
   "metadata": {},
   "source": [
    "この時出てくる逆伝播の値(微分)は「出力データに与える影響度の高さ」と考えるとわかりやすいと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63110d",
   "metadata": {},
   "source": [
    "## 実装(序)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a61f07f",
   "metadata": {},
   "source": [
    "先ほど示した計算グラフの例を実装してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c20727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乗算、加算レイヤの定義(レイヤとはニューラルネットワークの機能を一つにまとめたもの)\n",
    "\n",
    "class MulLayer: #乗算レイヤ\n",
    "    def __init__(self): #順伝播の入力信号の保持\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x, y): #順伝播の計算\n",
    "        self.x = x\n",
    "        self.y = y                \n",
    "        out = x * y\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout): #逆伝播の計算\n",
    "        dx = dout * self.y #dout=微分の値\n",
    "        dy = dout * self.x\n",
    "\n",
    "        return dx, dy\n",
    "\n",
    "\n",
    "class AddLayer: #加算レイヤ\n",
    "    def __init__(self):\n",
    "        pass #順伝播の入力信号は関係ない\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d3c1ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319.0\n",
      "110.00000000000001 2.2 3.3000000000000003 33.0 290\n"
     ]
    }
   ],
   "source": [
    "pencil=100 #鉛筆一本の値段\n",
    "pencil_num=2 #買った鉛筆の本数\n",
    "eraser=30 #消しゴム一個の値段\n",
    "eraser_num=3 #買った消しゴムの個数\n",
    "tax=1.1 #消費税\n",
    "\n",
    "mul_pencil_layer=MulLayer()\n",
    "mul_eraser_layer=MulLayer()\n",
    "add_pencil_eraser_layer=AddLayer()\n",
    "mul_tax_layer=MulLayer()\n",
    "\n",
    "pencil_price=mul_pencil_layer.forward(pencil,pencil_num) #鉛筆の値段の合計(税抜)\n",
    "eraser_price=mul_eraser_layer.forward(eraser,eraser_num) #消しゴムの値段の合計(税抜)\n",
    "all_price=add_pencil_eraser_layer.forward(pencil_price,eraser_price) #税抜価格\n",
    "price=mul_tax_layer.forward(all_price,tax) #税込価格\n",
    "\n",
    "dprice=1 #逆伝播\n",
    "dall_price,dtax=mul_tax_layer.backward(dprice)\n",
    "dpencil_price,deraser_price=add_pencil_eraser_layer.backward(dall_price)\n",
    "deraser,deraser_num=mul_eraser_layer.backward(deraser_price)\n",
    "dpencil,dpencil_num=mul_pencil_layer.backward(dpencil_price)\n",
    "\n",
    "print(price)\n",
    "print(dpencil_num,dpencil,deraser,deraser_num,dtax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa8185",
   "metadata": {},
   "source": [
    "## 実装(破)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68868c99",
   "metadata": {},
   "source": [
    "ここからは今までの実装で用いてきたような実際のニューラルネットワークの学習で使う関数をレイヤとして定義します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125416f7",
   "metadata": {},
   "source": [
    "### ReLUレイヤ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2b151e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common.functions import *\n",
    "from common.util import im2col, col2im\n",
    "\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53f4a349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]]\n",
      "[[False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "# mask変数の機能\n",
    "\n",
    "x=np.array([[1.0,-0.5],[-2.0,3.0]])\n",
    "print(x)\n",
    "mask=(x<=0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf5aa41",
   "metadata": {},
   "source": [
    "### Sigmoidレイヤ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ec3c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = sigmoid(x)\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d3dc25",
   "metadata": {},
   "source": [
    "### Affineレイヤ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb7682",
   "metadata": {},
   "source": [
    "ニュートラルネットワークの順伝播は行列の積です。そこでその計算(今まではnp.dot(X,W)といった風に計算していた)の順伝播、逆伝播を**Affineレイヤ**として実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e2f4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W =W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        # 重み・バイアスパラメータの微分\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a2d22c",
   "metadata": {},
   "source": [
    "### Softmax-with-Lossレイヤ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9adcf06",
   "metadata": {},
   "source": [
    "最後に出力層にあたるソフトマックス関数と損失関数である交差エントロピー誤差をまとめて**Softmax-with-Lossレイヤ**として実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1befac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None # 損失\n",
    "        self.y = None # softmaxの出力\n",
    "        self.t = None # 教師データ (one-hot vector)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1005ecd",
   "metadata": {},
   "source": [
    "## 実装(急)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02821d23",
   "metadata": {},
   "source": [
    "それでは誤差逆伝播法を導入していきましょう。まずは前回も行った二層ニューラルネットワークの実装からです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9388d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9466fb5",
   "metadata": {},
   "source": [
    "ここで前回行った数値微分と今回の誤差逆伝播法に本当に差はないのか検証します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d26dcd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:1.9147008829315543e-10\n",
      "b1:9.878135252632502e-10\n",
      "W2:6.984310773060221e-08\n",
      "b2:1.4036424991342723e-07\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
    "    print(key + \":\" + str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091ce1dd",
   "metadata": {},
   "source": [
    "値の小ささから勾配の差はかなり小さいとわかりました。とうとう実装です！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3faa4b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10255 0.1009\n",
      "0.7679333333333334 0.776\n",
      "0.87845 0.8815\n",
      "0.8992666666666667 0.9017\n",
      "0.90685 0.909\n",
      "0.9132 0.9166\n",
      "0.91845 0.9205\n",
      "0.9231833333333334 0.9253\n",
      "0.9254 0.9286\n",
      "0.92935 0.9317\n",
      "0.9324666666666667 0.9324\n",
      "0.9348 0.9352\n",
      "0.9363666666666667 0.9376\n",
      "0.939 0.9391\n",
      "0.9413166666666667 0.9403\n",
      "0.9431666666666667 0.9411\n",
      "0.94515 0.9432\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)\n",
    "\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad380e9",
   "metadata": {},
   "source": [
    "前回とは比べ物にならない速さで実装することができました！これで今章を終わりたいと思います。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
